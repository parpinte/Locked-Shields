{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "Here we will be creating a small set of functions that could be used to run different models\n",
    "- preprocess the datas\n",
    "- cleaning the datas\n",
    "- select a model of machine learning\n",
    "- train the model\n",
    "-"
   ],
   "id": "f1196527220e3fe8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T09:51:03.949144Z",
     "start_time": "2025-01-14T09:51:03.694147Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.tests.test__datasource import malicious_files\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:27:03.456635Z",
     "start_time": "2025-01-14T12:27:03.445400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.data = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "\n",
    "    # function to loas the data for that you need to have pandas imported as pd\n",
    "    def load_data(self):\n",
    "        \"\"\" here we will be loading the data from the path\"\"\"\n",
    "        try:\n",
    "            self.data = pd.read_csv(self.data_path, low_memory=False)\n",
    "            print(\"Data loaded successfully\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error loading data {self.data_path}\")\n",
    "\n",
    "    def clean_data(self, drop_missing_values=False, replace_inf = True, Fill_value = True):\n",
    "        \"\"\" here we will be cleaning the data\"\"\"\n",
    "        if drop_missing_values:\n",
    "            self.data.dropna(inplace=True)\n",
    "        if replace_inf:\n",
    "            self.data.replace([np.inf, -np.inf], Fill_value, inplace=True)\n",
    "\n",
    "    def show_features(self):\n",
    "        \"\"\" Display the features of the data\"\"\"\n",
    "        if self.data is not None:\n",
    "            print(\"features in the datasets: \")\n",
    "            for feature in self.data.columns:\n",
    "                print(f\"-{feature}\")\n",
    "        else: print(\"No data loaded\")\n",
    "\n",
    "    def drop_features(self, columns_to_drop):\n",
    "        \"\"\" Drop specific columns from the data\n",
    "        args : colums_to_drop (list) : list of columns names to be dropped\n",
    "        use the function show_features in order to checks the different features presents in the dataset\n",
    "        \"\"\"\n",
    "        if self.data is not None:\n",
    "            self.data.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "            print(\"Features dropped successfully\")\n",
    "        else: print(\"No data loaded. please doad the data first\")\n",
    "\n",
    "    def split_data(self, target_column):\n",
    "        \"\"\"\n",
    "        Splits the data into features (X) and target (y).\n",
    "        Args: target_column (str): The name of the column to be used as the target variable.\n",
    "        Returns: tuple: X (features), y (target)\n",
    "        \"\"\"\n",
    "        if self.data is not None:\n",
    "            if target_column in self.data.columns:\n",
    "                self.X = self.data.drop(columns=[target_column])\n",
    "                self.y = self.data[target_column]\n",
    "                print(f\"Data split into X (features) and y (target) using '{target_column}' as target.\")\n",
    "            else:\n",
    "                print(f\"Error: Column '{target_column}' not found in the dataset.\")\n",
    "\n",
    "        else:\n",
    "            print(\"No data loaded. Please load the data first.\")\n",
    "\n",
    "\n",
    "\n",
    "    def detect_categorical(self, handle_nan = \"unknown\"):\n",
    "        \"\"\"\n",
    "        Detects categorical features in the dataset and identifies NaN values.\n",
    "        Handles NaN values in the categorical features based on the chosen method.\n",
    "\n",
    "        Args: handle_nan (str): How to handle NaN values in categorical features.\n",
    "                              Options are \"drop\", \"most_frequent\", or \"unknown\".\n",
    "        \"\"\"\n",
    "        if self.data is not None:\n",
    "            # Detect categorical features\n",
    "            categorical_features = self.data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "            if len(categorical_features) == 0:\n",
    "                print(\"No categorical features detected.\")\n",
    "                return\n",
    "\n",
    "            print(\"Categorical Features and their NaN Information:\")\n",
    "            for feature in categorical_features:\n",
    "                total_nan = self.data[feature].isna().sum()\n",
    "                percentage_nan = (total_nan / len(self.data)) * 100\n",
    "\n",
    "                print(f\"- {feature}:\")\n",
    "                print(f\"  NaN Count: {total_nan}\")\n",
    "                print(f\"  Percentage of NaNs: {percentage_nan:.2f}%\")\n",
    "\n",
    "                # Handle NaN values based on the chosen option\n",
    "                if total_nan > 0:  # Only handle if there are NaN values\n",
    "                    if handle_nan == \"drop\":\n",
    "                        self.data.dropna(subset=[feature], inplace=True)\n",
    "                        print(f\"  Action: Dropped rows with NaN in '{feature}'.\")\n",
    "\n",
    "                    elif handle_nan == \"most_frequent\":\n",
    "                        most_frequent = self.data[feature].mode()[0]\n",
    "                        self.data[feature].fillna(most_frequent, inplace=True)\n",
    "                        print(f\"  Action: Replaced NaN with most frequent value '{most_frequent}'.\")\n",
    "\n",
    "                    elif handle_nan == \"unknown\":\n",
    "                        self.data[feature].fillna(\"Unknown\", inplace=True)\n",
    "                        print(f\"  Action: Replaced NaN with 'Unknown'.\")\n",
    "\n",
    "                    else:\n",
    "                        print(f\"  Action: Invalid option '{handle_nan}'. No changes made for '{feature}'.\")\n",
    "\n",
    "            print(\"\\nCategorical NaN handling completed.\")\n",
    "        else:\n",
    "            print(\"No data loaded. Please load the data first.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "2437661b6862873c",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:31:08.432660Z",
     "start_time": "2025-01-14T10:31:08.404992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\" main function to execute the script \"\"\"\n",
    "data = DataProcessor(\"balanced_data.csv\")\n",
    "\n"
   ],
   "id": "e8c544f1fda60173",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:32:33.740748Z",
     "start_time": "2025-01-14T10:31:08.980587Z"
    }
   },
   "cell_type": "code",
   "source": "data.load_data()\n",
   "id": "23090c0ba33f9c88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:32:33.917515Z",
     "start_time": "2025-01-14T10:32:33.915207Z"
    }
   },
   "cell_type": "code",
   "source": "data.show_features()",
   "id": "4d198d66863202a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features in the datasets: \n",
      "-Flow ID\n",
      "-SrcIP\n",
      "-DstIP\n",
      "-SrcPort\n",
      "-DstPort\n",
      "-Protocol\n",
      "-mTimestampStart\n",
      "-mTimestampLast\n",
      "-Flow Duration\n",
      "-Flow Bytes/s\n",
      "-Flow Packets/s\n",
      "-Tot Fwd Pkts\n",
      "-Tot Bwd Pkts\n",
      "-Total Length of Fwd Packet\n",
      "-Total Length of Bwd Packet\n",
      "-Fwd Packet Length Min\n",
      "-Fwd Packet Length Max\n",
      "-Fwd Packet Length Mean\n",
      "-Fwd Packet Length Std\n",
      "-Bwd Packet Length Min\n",
      "-Bwd Packet Length Max\n",
      "-Bwd Packet Length Mean\n",
      "-Bwd Packet Length Std\n",
      "-Flow IAT Mean\n",
      "-Flow IAT Min\n",
      "-Flow IAT Max\n",
      "-Flow IAT Stddev\n",
      "-Fwd IAT Min\n",
      "-Fwd IAT Max\n",
      "-Fwd IAT Mean\n",
      "-Fwd IAT Std\n",
      "-Fwd IAT Tot\n",
      "-Bwd IAT Min\n",
      "-Bwd IAT Max\n",
      "-Bwd IAT Mean\n",
      "-Bwd IAT Std\n",
      "-Bwd IAT Tot\n",
      "-Fwd PSH flags\n",
      "-Bwd PSH flags\n",
      "-Fwd URG flags\n",
      "-Bwd URG flags\n",
      "-Fwd Header Length\n",
      "-Bwd Header Length\n",
      "-Fwd Packets/s\n",
      "-Bwd Packets/s\n",
      "-Packet Length Min\n",
      "-Packet Length Max\n",
      "-Packet Length Mean\n",
      "-Packet Length Std\n",
      "-Packet Length Variance\n",
      "-FIN Flag Cnt\n",
      "-SYN Flag Cnt\n",
      "-RST Flag Cnt\n",
      "-PSH Flag Cnt\n",
      "-ACK Flag Cnt\n",
      "-URG Flag Cnt\n",
      "-CWR Flag Cnt\n",
      "-ECE Flag Cnt\n",
      "-Down/Up Ratio\n",
      "-Average Packet Size\n",
      "-Fwd Segment Size Avg\n",
      "-Bwd Segment Size Avg\n",
      "-Fwd Bytes/Bulk Avg\n",
      "-Fwd Packet/Bulk Avg\n",
      "-Fwd Bulk Rate Avg\n",
      "-Bwd Bytes/Bulk Avg\n",
      "-Bwd Packet/Bulk Avg\n",
      "-Bwd Bulk Rate Avg\n",
      "-Subflow Fwd Packets\n",
      "-Subflow Fwd Bytes\n",
      "-Subflow Bwd Packets\n",
      "-Subflow Bwd Bytes\n",
      "-FWD Init Win Bytes\n",
      "-Bwd Init Win Bytes\n",
      "-Fwd Act Data Pkts\n",
      "-Fwd Seg Size Min\n",
      "-Active Min\n",
      "-Active Mean\n",
      "-Active Max\n",
      "-Active Std\n",
      "-Idle Min\n",
      "-Idle Mean\n",
      "-Idle Max\n",
      "-Idle Std\n",
      "-L3/L4 Protocol\n",
      "-Int/Ext Dst IP\n",
      "-Conn_state\n",
      "-Service\n",
      "-Label\n",
      "-External_src\n",
      "-External_dst\n",
      "-Segment_src\n",
      "-Segment_dst\n",
      "-Expoid_src\n",
      "-Expoid_dst\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:32:34.999794Z",
     "start_time": "2025-01-14T10:32:34.492517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_drop = ['Flow ID', 'SrcIP', 'DstIP','External_src', 'External_dst','Conn_state', 'Segment_src', 'Segment_dst', 'Expoid_src', 'Expoid_dst','mTimestampStart','mTimestampLast']\n",
    "data.drop_features(columns_to_drop=columns_to_drop)"
   ],
   "id": "aea3de5fc060e682",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dropped successfully\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:32:35.313028Z",
     "start_time": "2025-01-14T10:32:35.077697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split data into dataset for the training and target\n",
    "data.split_data(target_column='Label')\n"
   ],
   "id": "45a78412c6271f39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into X (features) and y (target) using 'Label' as target.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:32:51.063593Z",
     "start_time": "2025-01-14T10:32:51.061763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(data.X.shape)\n",
    "print(data.y.shape)"
   ],
   "id": "61b1fbce65d19ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3289198, 82)\n",
      "(3289198,)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:26:18.841286Z",
     "start_time": "2025-01-14T10:26:18.839902Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec75a47492620db1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9a6fea2e8e4f63e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
