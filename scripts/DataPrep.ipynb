{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T07:55:27.370943Z",
     "start_time": "2025-01-21T07:55:27.369923Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## This class will allow us to perform different kinds of splits\n",
    "\n",
    "- Random Split\n",
    "- Manual Split\n",
    "- Chronological Split ( times series splitting )\n",
    "- Stratified Split : used for imbalanced datas\n",
    "- KFold Cross-Validation\n",
    "- Leave-One-Out Cross-validation"
   ],
   "id": "e65739f1d99b9586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T07:55:27.377784Z",
     "start_time": "2025-01-21T07:55:27.376535Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3637b4f76faf7be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T09:18:04.226573Z",
     "start_time": "2025-01-21T09:18:04.223803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n"
   ],
   "id": "534f49ac901cb4b",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T09:18:04.357654Z",
     "start_time": "2025-01-21T09:18:04.347443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DataSplitter:\n",
    "    def __init__(self, X=None, y=None):\n",
    "        \"\"\"\n",
    "        Initialize the DataSplitter with the dataset and target variable.\n",
    "            X (pd.DataFrame, optional): The features dataset.\n",
    "            y (pd.Series, optional): The target variable.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.splits = {}  # To store the training, validation, and test sets\n",
    "\n",
    "    def get_splits(self):\n",
    "        if not self.splits:\n",
    "            raise ValueError(\"No splits available. Please call a split method (e.g., `random_split`) first.\")\n",
    "        return self.splits\n",
    "\n",
    "    def load_from_csv(self, X_path, y_path):\n",
    "        \"\"\"\n",
    "        Load the feature dataset (X) and target variable (y) from CSV files.\n",
    "            X_path (str): Path to the CSV file containing the feature dataset.\n",
    "            y_path (str): Path to the CSV file containing the target variable.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.X = pd.read_csv(X_path)\n",
    "            self.y = pd.read_csv(y_path).squeeze()  # Ensure y is a Series, not a DataFrame\n",
    "            print(f\"Data loaded successfully:\\n- Features: {self.X.shape}\\n- Target: {self.y.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading data: {e}\")\n",
    "\n",
    "    def set_data(self, X, y):\n",
    "        \"\"\"\n",
    "        Set the feature dataset (X) and target variable (y) directly.\n",
    "            X (pd.DataFrame): Feature dataset.\n",
    "            y (pd.Series or pd.DataFrame): Target variable.\n",
    "\n",
    "        \"\"\"\n",
    "        # Validate input types\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            print(\"Error: X must be a pandas DataFrame.\")\n",
    "            return\n",
    "\n",
    "        if not isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            print(\"Error: y must be a pandas Series or DataFrame.\")\n",
    "            return\n",
    "\n",
    "        # Assign values\n",
    "        self.X = X\n",
    "        self.y = y.squeeze()  # Convert DataFrame to Series if necessary\n",
    "        print(f\"Data set successfully:\\n- Features: {self.X.shape}\\n- Target: {self.y.shape}\")\n",
    "\n",
    "    def random_split(self, test_size=0.2, val_size=0.0, random_state=42):\n",
    "        \"\"\"\n",
    "        Perform a random split of the dataset into training, validation, and test sets.\n",
    "            test_size\n",
    "            val_size\n",
    "            random_state (int): Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Data and target are not set. Use `load_from_csv` or `set_data` to initialize them.\")\n",
    "\n",
    "        # Split into train+validation and test\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        if val_size > 0:\n",
    "            # Adjust validation size relative to train+validation\n",
    "            val_relative_size = val_size / (1 - test_size)\n",
    "\n",
    "            # Split train+validation into train and validation\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val, test_size=val_relative_size, random_state=random_state\n",
    "            )\n",
    "\n",
    "            # Store splits\n",
    "            self.splits = {\n",
    "                \"train\": (X_train, y_train),\n",
    "                \"validation\": (X_val, y_val),\n",
    "                \"test\": (X_test, y_test),\n",
    "            }\n",
    "\n",
    "            print(f\"Random split completed:\\n- Train: {len(X_train)}\\n- Validation: {len(X_val)}\\n- Test: {len(X_test)}\")\n",
    "        else:\n",
    "            # No validation set; store train and test splits only\n",
    "            self.splits = {\n",
    "                \"train\": (X_train_val, y_train_val),\n",
    "                \"test\": (X_test, y_test),\n",
    "            }\n",
    "\n",
    "            print(f\"Random split completed:\\n- Train: {len(X_train_val)}\\n- Test: {len(X_test)}\")\n",
    "\n",
    "    def chronological_split(self, test_size=0.2, val_size=0.1, use_validation=False):\n",
    "        \"\"\"\n",
    "        Perform a chronological split of the dataset into training, validation, and test sets.\n",
    "        keep the earliers samples for the train and validation and the later for the test\n",
    "        please make sure that the data are sorted by date ( timestamp )\n",
    "            test_size (float)\n",
    "            val_size (float)\n",
    "            use_validation (bool)\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Data and target are not set. Use `load_from_csv` or `set_data` to initialize them.\")\n",
    "\n",
    "        # Total number of samples\n",
    "        n_samples = len(self.X)\n",
    "\n",
    "        # Calculate split indices\n",
    "        test_split_index = int(n_samples * (1 - test_size))\n",
    "        if use_validation:\n",
    "            val_split_index = int(test_split_index * (1 - val_size))\n",
    "        else:\n",
    "            val_split_index = test_split_index\n",
    "\n",
    "        # Create splits\n",
    "        X_train = self.X.iloc[:val_split_index]\n",
    "        y_train = self.y.iloc[:val_split_index]\n",
    "\n",
    "        if use_validation:\n",
    "            X_val = self.X.iloc[val_split_index:test_split_index]\n",
    "            y_val = self.y.iloc[val_split_index:test_split_index]\n",
    "        else:\n",
    "            X_val, y_val = None, None\n",
    "\n",
    "        X_test = self.X.iloc[test_split_index:]\n",
    "        y_test = self.y.iloc[test_split_index:]\n",
    "\n",
    "        # Store splits\n",
    "        self.splits = {\n",
    "            \"train\": (X_train, y_train),\n",
    "            \"validation\": (X_val, y_val) if use_validation else None,\n",
    "            \"test\": (X_test, y_test),\n",
    "        }\n",
    "\n",
    "        print(f\"Chronological split completed:\")\n",
    "        print(f\"- Train: {len(X_train)}\")\n",
    "        if use_validation:\n",
    "            print(f\"- Validation: {len(X_val)}\")\n",
    "        print(f\"- Test: {len(X_test)}\")\n",
    "\n",
    "    def stratified_split(self, test_size=0.2, val_size=0.1, random_state=42):\n",
    "        \"\"\"\n",
    "        Perform a stratified split of the dataset into training, validation, and test sets.\n",
    "            test_size (float): Proportion of the data to include in the test split.\n",
    "            val_size (float): Proportion of the training data to include in the validation split.\n",
    "            random_state (int): Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Data and target are not set. Use `load_from_csv` or `set_data` to initialize them.\")\n",
    "\n",
    "        # Split into train+validation and test\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state, stratify=self.y\n",
    "        )\n",
    "\n",
    "        if val_size > 0:\n",
    "            # Adjust validation size relative to train+validation\n",
    "            val_relative_size = val_size / (1 - test_size)\n",
    "\n",
    "            # Split train+validation into train and validation\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_val, y_train_val, test_size=val_relative_size, random_state=random_state, stratify=y_train_val\n",
    "            )\n",
    "\n",
    "            # Store splits\n",
    "            self.splits = {\n",
    "                \"train\": (X_train, y_train),\n",
    "                \"validation\": (X_val, y_val),\n",
    "                \"test\": (X_test, y_test),\n",
    "            }\n",
    "\n",
    "            print(f\"Stratified split completed:\\n- Train: {len(X_train)}\\n- Validation: {len(X_val)}\\n- Test: {len(X_test)}\")\n",
    "        else:\n",
    "            # No validation set; store train and test splits only\n",
    "            self.splits = {\n",
    "                \"train\": (X_train_val, y_train_val),\n",
    "                \"test\": (X_test, y_test),\n",
    "            }\n",
    "\n",
    "            print(f\"Stratified split completed:\\n- Train: {len(X_train_val)}\\n- Test: {len(X_test)}\")\n",
    "\n",
    "\n",
    "    def kfold_split(self, n_splits=5, shuffle=False, random_state=None):\n",
    "        \"\"\"\n",
    "        Perform K-Fold Cross-Validation split on the dataset.\n",
    "            n_splits (int): Number of folds (k).\n",
    "            shuffle (bool): Whether to shuffle the data before splitting.\n",
    "            random_state (int): Random seed for reproducibility (used when shuffle=True).\n",
    "\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Data and target are not set. Use `load_from_csv` or `set_data` to initialize them.\")\n",
    "\n",
    "        # Initialize KFold\n",
    "        kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "        # Store splits\n",
    "        self.splits = []\n",
    "        fold_idx = 1\n",
    "\n",
    "        for train_index, val_index in kf.split(self.X):\n",
    "            X_train, X_val = self.X.iloc[train_index], self.X.iloc[val_index]\n",
    "            y_train, y_val = self.y.iloc[train_index], self.y.iloc[val_index]\n",
    "\n",
    "            self.splits.append({\n",
    "                \"train\": (X_train, y_train),\n",
    "                \"validation\": (X_val, y_val),\n",
    "            })\n",
    "\n",
    "            print(f\"Fold {fold_idx} created:\")\n",
    "            print(f\"- Train: {len(train_index)} samples\")\n",
    "            print(f\"- Validation: {len(val_index)} samples\")\n",
    "            fold_idx += 1\n",
    "\n",
    "\n",
    "    def leave_one_out_split(self):\n",
    "        \"\"\"\n",
    "        Perform Leave-One-Out Cross-Validation (LOOCV) on the dataset.\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Data and target are not set. Use `load_from_csv` or `set_data` to initialize them.\")\n",
    "        # Initialize LeaveOneOut\n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "        # Store splits\n",
    "        self.splits = []\n",
    "        fold_idx = 1\n",
    "\n",
    "        for train_index, val_index in loo.split(self.X):\n",
    "            X_train, X_val = self.X.iloc[train_index], self.X.iloc[val_index]\n",
    "            y_train, y_val = self.y.iloc[train_index], self.y.iloc[val_index]\n",
    "\n",
    "            self.splits.append({\n",
    "                \"train\": (X_train, y_train),\n",
    "                \"validation\": (X_val, y_val),\n",
    "            })\n",
    "\n",
    "            print(f\"Fold {fold_idx} created:\")\n",
    "            print(f\"- Train: {len(train_index)} samples\")\n",
    "            print(f\"- Validation: 1 sample\")\n",
    "            fold_idx += 1\n",
    "\n",
    "\n",
    "    def save_splits(self, output_dir, file_format=\"csv\"):\n",
    "        \"\"\"\n",
    "        Save the splits to files in a specified folder.\n",
    "            output_dir (str): Path to the folder where the splits will be saved.\n",
    "            file_format (str): File format for saving ('csv' or 'excel').\n",
    "        \"\"\"\n",
    "        if not self.splits:\n",
    "            raise ValueError(\"No splits available. Please perform a split method first.\")\n",
    "\n",
    "        # Create the output directory if it doesn't exist\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Save each split\n",
    "        for split_name, split_data in self.splits.items():\n",
    "            if split_data is not None:\n",
    "                X, y = split_data\n",
    "                if file_format == \"csv\":\n",
    "                    X.to_csv(os.path.join(output_dir, f\"{split_name}_X.csv\"), index=False)\n",
    "                    y.to_csv(os.path.join(output_dir, f\"{split_name}_y.csv\"), index=False)\n",
    "                elif file_format == \"excel\":\n",
    "                    X.to_excel(os.path.join(output_dir, f\"{split_name}_X.xlsx\"), index=False)\n",
    "                    y.to_excel(os.path.join(output_dir, f\"{split_name}_y.xlsx\"), index=False)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid file format. Use 'csv' or 'excel'.\")\n",
    "\n",
    "        print(f\"Splits saved successfully in '{output_dir}'.\")\n",
    "\n",
    "\n"
   ],
   "id": "16d1a060613c480b",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T09:18:04.681714Z",
     "start_time": "2025-01-21T09:18:04.501408Z"
    }
   },
   "cell_type": "code",
   "source": "Split = DataSplitter()",
   "id": "de05bdf65e7d1897",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T09:18:15.422053Z",
     "start_time": "2025-01-21T09:18:04.689178Z"
    }
   },
   "cell_type": "code",
   "source": "Split.load_from_csv(\"../data/test_1/processed_data.csv\", \"../data/test_1/processed_target.csv\")",
   "id": "e20abd5ceb715f76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "- Features: (1771194, 74)\n",
      "- Target: (1771194,)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-21T09:18:15.494377Z"
    }
   },
   "cell_type": "code",
   "source": "Split.leave_one_out_split()",
   "id": "8984b19b83d9727f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 2 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 3 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 4 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 5 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 6 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 7 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 8 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 9 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 10 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 11 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 12 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 13 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 14 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 15 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 16 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 17 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 18 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 19 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 20 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 21 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 22 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 23 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 24 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 25 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 26 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 27 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 28 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 29 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 30 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 31 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 32 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 33 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 34 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 35 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 36 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 37 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 38 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 39 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 40 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 41 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 42 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 43 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 44 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 45 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 46 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 47 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 48 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 49 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 50 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 51 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 52 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n",
      "Fold 53 created:\n",
      "- Train: 1771193 samples\n",
      "- Validation: 1 sample\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T09:14:21.534636Z",
     "start_time": "2025-01-21T09:14:21.532958Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ea798ff58e14b1d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T09:14:21.546998Z",
     "start_time": "2025-01-21T09:14:21.545772Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "75f0bb0c0e79eef7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T07:55:27.533850Z",
     "start_time": "2025-01-21T07:55:27.532347Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3e53f62597b3c234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55343ebd7fc339e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
